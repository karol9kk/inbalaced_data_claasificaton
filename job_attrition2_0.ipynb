{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.dropna of       Age  Attrition     BusinessTravel  DailyRate              Department  \\\n",
       "0      41          1      Travel_Rarely       1102                   Sales   \n",
       "1      49          0  Travel_Frequently        279  Research & Development   \n",
       "2      37          1      Travel_Rarely       1373  Research & Development   \n",
       "3      33          0  Travel_Frequently       1392  Research & Development   \n",
       "4      27          0      Travel_Rarely        591  Research & Development   \n",
       "...   ...        ...                ...        ...                     ...   \n",
       "1465   36          0  Travel_Frequently        884  Research & Development   \n",
       "1466   39          0      Travel_Rarely        613  Research & Development   \n",
       "1467   27          0      Travel_Rarely        155  Research & Development   \n",
       "1468   49          0  Travel_Frequently       1023                   Sales   \n",
       "1469   34          0      Travel_Rarely        628  Research & Development   \n",
       "\n",
       "      DistanceFromHome  Education EducationField  EmployeeCount  \\\n",
       "0                    1          2  Life Sciences              1   \n",
       "1                    8          1  Life Sciences              1   \n",
       "2                    2          2          Other              1   \n",
       "3                    3          4  Life Sciences              1   \n",
       "4                    2          1        Medical              1   \n",
       "...                ...        ...            ...            ...   \n",
       "1465                23          2        Medical              1   \n",
       "1466                 6          1        Medical              1   \n",
       "1467                 4          3  Life Sciences              1   \n",
       "1468                 2          3        Medical              1   \n",
       "1469                 8          3        Medical              1   \n",
       "\n",
       "      EmployeeNumber  ...  RelationshipSatisfaction StandardHours  \\\n",
       "0                  1  ...                         1            80   \n",
       "1                  2  ...                         4            80   \n",
       "2                  4  ...                         2            80   \n",
       "3                  5  ...                         3            80   \n",
       "4                  7  ...                         4            80   \n",
       "...              ...  ...                       ...           ...   \n",
       "1465            2061  ...                         3            80   \n",
       "1466            2062  ...                         1            80   \n",
       "1467            2064  ...                         2            80   \n",
       "1468            2065  ...                         4            80   \n",
       "1469            2068  ...                         1            80   \n",
       "\n",
       "      StockOptionLevel  TotalWorkingYears  TrainingTimesLastYear  \\\n",
       "0                    0                  8                      0   \n",
       "1                    1                 10                      3   \n",
       "2                    0                  7                      3   \n",
       "3                    0                  8                      3   \n",
       "4                    1                  6                      3   \n",
       "...                ...                ...                    ...   \n",
       "1465                 1                 17                      3   \n",
       "1466                 1                  9                      5   \n",
       "1467                 1                  6                      0   \n",
       "1468                 0                 17                      3   \n",
       "1469                 0                  6                      3   \n",
       "\n",
       "     WorkLifeBalance  YearsAtCompany YearsInCurrentRole  \\\n",
       "0                  1               6                  4   \n",
       "1                  3              10                  7   \n",
       "2                  3               0                  0   \n",
       "3                  3               8                  7   \n",
       "4                  3               2                  2   \n",
       "...              ...             ...                ...   \n",
       "1465               3               5                  2   \n",
       "1466               3               7                  7   \n",
       "1467               3               6                  2   \n",
       "1468               2               9                  6   \n",
       "1469               4               4                  3   \n",
       "\n",
       "      YearsSinceLastPromotion  YearsWithCurrManager  \n",
       "0                           0                     5  \n",
       "1                           1                     7  \n",
       "2                           0                     0  \n",
       "3                           3                     0  \n",
       "4                           2                     2  \n",
       "...                       ...                   ...  \n",
       "1465                        0                     3  \n",
       "1466                        1                     7  \n",
       "1467                        0                     3  \n",
       "1468                        0                     8  \n",
       "1469                        1                     2  \n",
       "\n",
       "[1470 rows x 35 columns]>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(r\"D:\\data\\WA_Fn-UseC_-HR-Employee-Attrition.csv\")\n",
    "df.columns\n",
    "df['Attrition'] = df['Attrition'].map({'Yes': 1, 'No': 0}) # zmieniamy wartości na Boolean\n",
    "df.dropna # odrzucamy wiersze z wartościami NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1470, 34)\n",
      "Number of positive: 237, number of negative: 1233\n"
     ]
    }
   ],
   "source": [
    "# zmienna określana Attrition\n",
    "Y = df['Attrition'].values\n",
    "X = df.drop('Attrition', axis=1).values\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "# sprwadzamy zbilansowanie zbioru\n",
    "n_pos = (Y == 1).sum()\n",
    "n_neg = (Y == 0).sum()\n",
    "\n",
    "# not well balanced\n",
    "print(f\"Number of positive: {n_pos}, number of negative: {n_neg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, accuracy_score,classification_report,roc_auc_score\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.pipeline import Pipeline, make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#podział na zbiór trenignowy i testowy\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1102, 4315)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#zamiana cech jakoścowych na n cech binarnych\n",
    "\n",
    "def one_hot_encode(X_train, X_test):\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    \n",
    "    X_train_enc = enc.fit_transform(X_train)\n",
    "\n",
    "    # Transform the testing data using the same encoder\n",
    "    X_test_enc = enc.transform(X_test)\n",
    "\n",
    "    return X_train_enc, X_test_enc\n",
    "\n",
    "X_train_enc,X_test_enc=one_hot_encode(X_train, X_test)\n",
    "print(X_train_enc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "def data_oversampling()->tuple:\n",
    "\n",
    "    name=\"Oversampling\"\n",
    "\n",
    "    oversample = RandomOverSampler(sampling_strategy=0.7,random_state=42)\n",
    "\n",
    "    return(oversample,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "def data_undersampling()->tuple:\n",
    "\n",
    "    name=\"Undersampling\"\n",
    "    \n",
    "    undersample = RandomUnderSampler(sampling_strategy=0.7,random_state=42)\n",
    "\n",
    "    return (undersample,name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def data_smote()-> tuple:\n",
    "\n",
    "    name=\"SMOTE\"\n",
    "    smote=SMOTE(random_state=42)\n",
    "   \n",
    "\n",
    "    return (smote,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "func_list=[data_oversampling,data_undersampling,data_smote]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def decison_tree(func_list: list,params: dict) -> None: \n",
    "    \n",
    "    #ramka danych do przechowywania wyników\n",
    "    df_score = pd.DataFrame(columns=['Random forest with','Recall','Precision','F1 Score', 'Accuracy','Roc Auc'])\n",
    "    \n",
    "    # iterujemy po wektorze z funkcjami\n",
    "    for func in func_list:\n",
    "        #tworzymy pipeline\n",
    "        pipeline = make_pipeline(func()[0], \n",
    "                                  RandomForestClassifier(criterion='gini',n_estimators=100, random_state=42))\n",
    "        \n",
    "        #werfyikacja kryżowa\n",
    "        new_params = {'randomforestclassifier__' + key: params[key] for key in params}\n",
    "        grid_search = GridSearchCV(pipeline, param_grid=new_params, cv=3, scoring='f1',\n",
    "                                return_train_score=True,n_jobs=-1)\n",
    "        grid_search.fit(X_train_enc,Y_train)\n",
    "        print(grid_search.best_params_)\n",
    "        random_forest_best=grid_search.best_estimator_\n",
    "        pos_prob=random_forest_best.predict_proba(X_test_enc)[:,1]\n",
    "\n",
    "\n",
    "        pred=random_forest_best.predict(X_test_enc)\n",
    "        \n",
    "        #dokładnośc modelu\n",
    "        cm = confusion_matrix(Y_test,pred)\n",
    "        print(cm)\n",
    " \n",
    "        roc_auc=roc_auc_score(Y_test,pos_prob)\n",
    "        recall = recall_score(Y_test,pred)\n",
    "        precision = precision_score(Y_test,pred)\n",
    "        f1 = f1_score(Y_test,pred)\n",
    "        accuracy = accuracy_score(Y_test,pred)\n",
    "        \n",
    "        #zapisujemy dane do ramki danych\n",
    "\n",
    "        ndf = [func()[1],recall, precision, f1, accuracy,roc_auc]\n",
    "\n",
    "        df_score=df_score.append(pd.Series(ndf, index=df_score.columns[:len(ndf)]), ignore_index=True)\n",
    "        \n",
    "    \n",
    "    display(df_score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def random_forest(func_list: list,params: dict) -> None: \n",
    "    \n",
    "    #ramka danych do przechowywania wyników\n",
    "    df_score = pd.DataFrame(columns=['Decison tree with','Recall','Precision','F1 Score', 'Accuracy','Roc Auc'])\n",
    "    \n",
    "    # iterujemy po wektorze z funkcjami\n",
    "    for func in func_list:\n",
    "        #tworzymy pipeline\n",
    "        pipeline = make_pipeline(func()[0], \n",
    "                                  DecisionTreeClassifier(random_state=42))\n",
    "        \n",
    "        #werfyikacja kryżowa\n",
    "        new_params = {'deciosntreeclassifier__' + key: params[key] for key in params}\n",
    "        grid_search = GridSearchCV(pipeline, param_grid=new_params, cv=3, scoring='f1',\n",
    "                                return_train_score=True,n_jobs=-1)\n",
    "        grid_search.fit(X_train_enc,Y_train)\n",
    "        print(grid_search.best_params_)\n",
    "        decision_tree_best=grid_search.best_estimator_\n",
    "        pos_prob=decision_tree_best.predict_proba(X_test_enc)[:,1]\n",
    "\n",
    "\n",
    "        pred=decision_tree_best.predict(X_test_enc)\n",
    "        \n",
    "        #dokładnośc modelu\n",
    "        cm = confusion_matrix(Y_test,pred)\n",
    "        print(cm)\n",
    " \n",
    "        roc_auc=roc_auc_score(Y_test,pos_prob)\n",
    "        recall = recall_score(Y_test,pred)\n",
    "        precision = precision_score(Y_test,pred)\n",
    "        f1 = f1_score(Y_test,pred)\n",
    "        accuracy = accuracy_score(Y_test,pred)\n",
    "        \n",
    "        #zapisujemy dane do ramki danych\n",
    "\n",
    "        ndf = [func()[1],recall, precision, f1, accuracy,roc_auc]\n",
    "\n",
    "        df_score=df_score.append(pd.Series(ndf, index=df_score.columns[:len(ndf)]), ignore_index=True)\n",
    "        \n",
    "    \n",
    "    display(df_score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(func_list: list,params: dict) -> None: \n",
    "    \n",
    "    #ramka danych do przechowywania wyników\n",
    "    df_score = pd.DataFrame(columns=['Random forest with','Recall','Precision','F1 Score', 'Accuracy','Roc Auc'])\n",
    "    \n",
    "    # iterujemy po wektorze z funkcjami\n",
    "    for func in func_list:\n",
    "        #tworzymy pipeline\n",
    "        pipeline = make_pipeline(func()[0], \n",
    "                                  RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "        \n",
    "        #werfyikacja kryżowa\n",
    "        new_params = {'randomforestclassifier__' + key: params[key] for key in params}\n",
    "        grid_search = GridSearchCV(pipeline, param_grid=new_params, cv=3, scoring='f1',\n",
    "                                return_train_score=True,n_jobs=-1)\n",
    "        grid_search.fit(X_train_enc,Y_train)\n",
    "        print(grid_search.best_params_)\n",
    "        random_forest_best=grid_search.best_estimator_\n",
    "        pos_prob=random_forest_best.predict_proba(X_test_enc)[:,1]\n",
    "\n",
    "\n",
    "        pred=random_forest_best.predict(X_test_enc)\n",
    "        \n",
    "        #dokładnośc modelu\n",
    "        cm = confusion_matrix(Y_test,pred)\n",
    "        print(cm)\n",
    " \n",
    "        roc_auc=roc_auc_score(Y_test,pos_prob)\n",
    "        recall = recall_score(Y_test,pred)\n",
    "        precision = precision_score(Y_test,pred)\n",
    "        f1 = f1_score(Y_test,pred)\n",
    "        accuracy = accuracy_score(Y_test,pred)\n",
    "        \n",
    "        #zapisujemy dane do ramki danych\n",
    "\n",
    "        ndf = [func()[1],recall, precision, f1, accuracy,roc_auc]\n",
    "\n",
    "        df_score=df_score.append(pd.Series(ndf, index=df_score.columns[:len(ndf)]), ignore_index=True)\n",
    "        \n",
    "    \n",
    "    display(df_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc(func_list: list,params: dict) -> None: \n",
    "    \n",
    "    #ramka danych do przechowywania wyników\n",
    "    df_score = pd.DataFrame(columns=['SVC with','Recall','Precision','F1 Score', 'Accuracy','Roc Auc'])\n",
    "    \n",
    "    # iterujemy po wektorze z funkcjami\n",
    "    for func in func_list:\n",
    "        #tworzymy pipeline\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocess', preprocess),\n",
    "            ('model', ())\n",
    "        ])\n",
    "\n",
    "        \n",
    "        #werfyikacja kryżowa\n",
    "        new_params = {'svcclassifier__' + key: params[key] for key in params}\n",
    "        grid_search = GridSearchCV(pipeline, param_grid=new_params, cv=3, scoring='f1',\n",
    "                                return_train_score=True,n_jobs=-1)\n",
    "        grid_search.fit(X_train_enc,Y_train)\n",
    "        print(grid_search.best_params_)\n",
    "        svc_best=grid_search.best_estimator_\n",
    "        pos_prob=svc_best.predict_proba(X_test_enc)[:,1]\n",
    "\n",
    "\n",
    "        pred=svc_best.predict(X_test_enc)\n",
    "        \n",
    "        #dokładnośc modelu\n",
    "        cm = confusion_matrix(Y_test,pred)\n",
    "        print(cm)\n",
    " \n",
    "        roc_auc=roc_auc_score(Y_test,pos_prob)\n",
    "        recall = recall_score(Y_test,pred)\n",
    "        precision = precision_score(Y_test,pred)\n",
    "        f1 = f1_score(Y_test,pred)\n",
    "        accuracy = accuracy_score(Y_test,pred)\n",
    "        \n",
    "        #zapisujemy dane do ramki danych\n",
    "\n",
    "        ndf = [func()[1],recall, precision, f1, accuracy,roc_auc]\n",
    "\n",
    "        df_score=df_score.append(pd.Series(ndf, index=df_score.columns[:len(ndf)]), ignore_index=True)\n",
    "        \n",
    "    \n",
    "    display(df_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestclassifier__max_depth': None, 'randomforestclassifier__min_samples_leaf': 2, 'randomforestclassifier__min_samples_split': 50}\n",
      "[[312   8]\n",
      " [ 40   8]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karol\\AppData\\Local\\Temp\\ipykernel_15832\\667122590.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_score=df_score.append(pd.Series(ndf, index=df_score.columns[:len(ndf)]), ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestclassifier__max_depth': None, 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 10}\n",
      "[[303  17]\n",
      " [ 36  12]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karol\\AppData\\Local\\Temp\\ipykernel_15832\\667122590.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_score=df_score.append(pd.Series(ndf, index=df_score.columns[:len(ndf)]), ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestclassifier__max_depth': 5, 'randomforestclassifier__min_samples_leaf': 3, 'randomforestclassifier__min_samples_split': 50}\n",
      "[[299  21]\n",
      " [ 37  11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karol\\AppData\\Local\\Temp\\ipykernel_15832\\667122590.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_score=df_score.append(pd.Series(ndf, index=df_score.columns[:len(ndf)]), ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random forest with</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Oversampling</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.748503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Undersampling</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.311688</td>\n",
       "      <td>0.855978</td>\n",
       "      <td>0.759961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.842391</td>\n",
       "      <td>0.729036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Random forest with    Recall  Precision  F1 Score  Accuracy   Roc Auc\n",
       "0       Oversampling  0.166667   0.500000  0.250000  0.869565  0.748503\n",
       "1      Undersampling  0.250000   0.413793  0.311688  0.855978  0.759961\n",
       "2              SMOTE  0.229167   0.343750  0.275000  0.842391  0.729036"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params_deciosn_tree = {'max_depth': [5,10,None],\n",
    "                    'min_samples_split': [10, 30, 50],\n",
    "                    'min_samples_leaf': [1, 2, 3]}\n",
    "\n",
    "decison_tree(func_list,params_deciosn_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_random_forest={'max_depth': [5, 10, None],\n",
    "                    'min_samples_split': [10, 30, 50],\n",
    "                    'min_samples_leaf': [1, 2, 3]}\n",
    "random_forest(func_list,params_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'svcclassifier' for estimator Pipeline(steps=[('randomoversampler',\n                 RandomOverSampler(random_state=42, sampling_strategy=0.7)),\n                ('svc', SVC(probability=True, random_state=42))]). Valid parameters are: ['memory', 'steps', 'verbose'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\karol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 463, in _process_worker\n    r = call_item()\n  File \"c:\\Users\\karol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"c:\\Users\\karol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\", line 589, in __call__\n    return [func(*args, **kwargs)\n  File \"c:\\Users\\karol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\", line 589, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"c:\\Users\\karol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 127, in __call__\n    return self.function(*args, **kwargs)\n  File \"c:\\Users\\karol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 717, in _fit_and_score\n    estimator = estimator.set_params(**clone(parameters, safe=False))\n  File \"c:\\Users\\karol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 222, in set_params\n    self._set_params(\"steps\", **kwargs)\n  File \"c:\\Users\\karol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 68, in _set_params\n    super().set_params(**params)\n  File \"c:\\Users\\karol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 230, in set_params\n    raise ValueError(\nValueError: Invalid parameter 'svcclassifier' for estimator Pipeline(steps=[('randomoversampler',\n                 RandomOverSampler(random_state=42, sampling_strategy=0.7)),\n                ('svc', SVC(probability=True, random_state=42))]). Valid parameters are: ['memory', 'steps', 'verbose'].\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\karol\\Desktop\\machine_learning\\job_attrition\\job_attrition2_0.ipynb Cell 16\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karol/Desktop/machine_learning/job_attrition/job_attrition2_0.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m paramas_svc\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m0.25\u001b[39m,\u001b[39m0.5\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karol/Desktop/machine_learning/job_attrition/job_attrition2_0.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mgamma\u001b[39m\u001b[39m\"\u001b[39m:[\u001b[39m1e-07\u001b[39m,\u001b[39m1e-08\u001b[39m,\u001b[39m1e-09\u001b[39m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karol/Desktop/machine_learning/job_attrition/job_attrition2_0.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mkernel\u001b[39m\u001b[39m'\u001b[39m:[\u001b[39m'\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m'\u001b[39m]}\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/karol/Desktop/machine_learning/job_attrition/job_attrition2_0.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m svc(func_list,paramas_svc)\n",
      "\u001b[1;32mc:\\Users\\karol\\Desktop\\machine_learning\\job_attrition\\job_attrition2_0.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/karol/Desktop/machine_learning/job_attrition/job_attrition2_0.ipynb#X21sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m new_params \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39msvcclassifier__aa\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m key: params[key] \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m params}\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/karol/Desktop/machine_learning/job_attrition/job_attrition2_0.ipynb#X21sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(pipeline, param_grid\u001b[39m=\u001b[39mnew_params, cv\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mf1\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/karol/Desktop/machine_learning/job_attrition/job_attrition2_0.ipynb#X21sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                         return_train_score\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/karol/Desktop/machine_learning/job_attrition/job_attrition2_0.ipynb#X21sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(X_train_enc,Y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/karol/Desktop/machine_learning/job_attrition/job_attrition2_0.ipynb#X21sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(grid_search\u001b[39m.\u001b[39mbest_params_)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/karol/Desktop/machine_learning/job_attrition/job_attrition2_0.ipynb#X21sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m svc_best\u001b[39m=\u001b[39mgrid_search\u001b[39m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32mc:\\Users\\karol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\karol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\karol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1421\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\karol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\karol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\karol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n",
      "File \u001b[1;32mc:\\Users\\karol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\karol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1692\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1693\u001b[0m \n\u001b[0;32m   1694\u001b[0m     \u001b[39m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1695\u001b[0m     \u001b[39m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[39m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1697\u001b[0m     \u001b[39m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aborting:\n\u001b[1;32m-> 1699\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_error_fast()\n\u001b[0;32m   1700\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m   1702\u001b[0m     \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m     \u001b[39m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\karol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1734\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1730\u001b[0m \u001b[39m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m \u001b[39m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1732\u001b[0m \u001b[39m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1733\u001b[0m \u001b[39mif\u001b[39;00m error_job \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1734\u001b[0m     error_job\u001b[39m.\u001b[39;49mget_result(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout)\n",
      "File \u001b[1;32mc:\\Users\\karol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:736\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    730\u001b[0m backend \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparallel\u001b[39m.\u001b[39m_backend\n\u001b[0;32m    732\u001b[0m \u001b[39mif\u001b[39;00m backend\u001b[39m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    733\u001b[0m     \u001b[39m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    734\u001b[0m     \u001b[39m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    735\u001b[0m     \u001b[39m# be returned.\u001b[39;00m\n\u001b[1;32m--> 736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_return_or_raise()\n\u001b[0;32m    738\u001b[0m \u001b[39m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\karol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:754\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    753\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 754\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n\u001b[0;32m    755\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n\u001b[0;32m    756\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter 'svcclassifier' for estimator Pipeline(steps=[('randomoversampler',\n                 RandomOverSampler(random_state=42, sampling_strategy=0.7)),\n                ('svc', SVC(probability=True, random_state=42))]). Valid parameters are: ['memory', 'steps', 'verbose']."
     ]
    }
   ],
   "source": [
    "paramas_svc={\"C\": [0.25,0.5,1,2,3],\n",
    "            \"gamma\":[1e-07,1e-08,1e-09],\n",
    "            'kernel':['linear']}\n",
    "svc(func_list,paramas_svc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
